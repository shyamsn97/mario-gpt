#!/usr/bin/env python

from transformers import AutoModelWithLMHead, AutoTokenizer, BartModel, BartTokenizerFast
from transformers.utils.hub import move_cache


MODEL_CACHE = "/src/transformers-cache"
MODEL_ID = "shyamsn97/Mario-GPT2-700-context-length"

feature_extractor = BartModel.from_pretrained("facebook/bart-base", cache_dir=MODEL_CACHE)
bart_tokenizer = BartTokenizerFast.from_pretrained("facebook/bart-base", cache_dir=MODEL_CACHE)
tokenizer = AutoTokenizer.from_pretrained(MODEL_ID, add_cross_attention=True, cache_dir=MODEL_CACHE)
model = AutoModelWithLMHead.from_pretrained(MODEL_ID, add_cross_attention=True, cache_dir=MODEL_CACHE)

move_cache("/src/transformers-cache", "/src/transformers-cache")
